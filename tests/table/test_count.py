"""
Unit tests for the DataScan.count() method in PyIceberg.

The count() method is essential for determining the number of rows in an Iceberg table
without having to load the actual data. It works by examining file metadata and task
plans to efficiently calculate row counts across distributed data files.

These tests validate the count functionality across different scenarios:
1. Basic counting with single file tasks
2. Empty table handling (zero records)
3. Large-scale counting with multiple file tasks

The tests use mocking to simulate different table states without requiring actual
Iceberg table infrastructure, ensuring fast and isolated unit tests.
"""

import pytest
from unittest.mock import MagicMock, Mock, patch
from pyiceberg.table import DataScan
from pyiceberg.expressions import AlwaysTrue


class DummyFile:
    """
    Mock representation of an Iceberg data file.

    In real scenarios, this would contain metadata about Parquet files
    including record counts, file paths, and statistics.
    """
    def __init__(self, record_count):
        self.record_count = record_count


class DummyTask:
    """
    Mock representation of a scan task in Iceberg query planning.

    A scan task represents work to be done on a specific data file,
    including any residual filters and delete files that need to be applied.
    In actual usage, tasks are generated by the query planner based on
    partition pruning and filter pushdown optimizations.
    """
    def __init__(self, record_count, residual=None, delete_files=None):
        self.file = DummyFile(record_count)
        self.residual = residual if residual is not None else AlwaysTrue()
        self.delete_files = delete_files or []

def test_count_basic():
    """
    Test basic count functionality with a single file containing data.

    This test verifies that the count() method correctly aggregates record counts
    from a single scan task. It simulates a table with one data file containing
    42 records and validates that the count method returns the correct total.

    The test demonstrates the typical use case where:
    - A table has one or more data files
    - Each file has metadata containing record counts
    - The count() method aggregates these counts efficiently
    """
    # Create a mock table with the necessary attributes
    scan = Mock(spec=DataScan)

    # Mock the plan_files method to return our dummy task
    task = DummyTask(42, residual=AlwaysTrue(), delete_files=[])
    scan.plan_files = MagicMock(return_value=[task])

    # Import and call the actual count method
    from pyiceberg.table import DataScan as ActualDataScan
    scan.count = ActualDataScan.count.__get__(scan, ActualDataScan)

    assert scan.count() == 42


def test_count_empty():
    """
    Test count functionality on an empty table.

    This test ensures that the count() method correctly handles empty tables
    that have no data files or scan tasks. It validates that an empty table
    returns a count of 0 without raising any errors.

    This scenario is important for:
    - Newly created tables before any data is inserted
    - Tables where all data has been deleted
    - Tables with restrictive filters that match no data
    """
    # Create a mock table with the necessary attributes
    scan = Mock(spec=DataScan)

    # Mock the plan_files method to return no tasks
    scan.plan_files = MagicMock(return_value=[])

    # Import and call the actual count method
    from pyiceberg.table import DataScan as ActualDataScan
    scan.count = ActualDataScan.count.__get__(scan, ActualDataScan)

    assert scan.count() == 0


def test_count_large():
    """
    Test count functionality with multiple files containing large datasets.

    This test validates that the count() method can efficiently handle tables
    with multiple data files and large record counts. It simulates a distributed
    scenario where data is split across multiple files, each containing 500,000
    records, for a total of 1 million records.

    This test covers:
    - Aggregation across multiple scan tasks
    - Handling of large record counts (performance implications)
    - Distributed data scenarios common in big data environments
    """
    # Create a mock table with the necessary attributes
    scan = Mock(spec=DataScan)

    # Mock the plan_files method to return multiple tasks
    tasks = [
        DummyTask(500000, residual=AlwaysTrue(), delete_files=[]),
        DummyTask(500000, residual=AlwaysTrue(), delete_files=[]),
    ]
    scan.plan_files = MagicMock(return_value=tasks)

    # Import and call the actual count method
    from pyiceberg.table import DataScan as ActualDataScan
    scan.count = ActualDataScan.count.__get__(scan, ActualDataScan)

    assert scan.count() == 1000000